% !TEX root = main.tex

\addtocontents{toc}{\protect\newpage}
\secc[Planning]{Project Planning}

\ssecc{Planning and scheduling}

The estimated project duration is of about 4 months. The project starts on Wednesday 14th of 
February, 2018 and the deadline is on Sunday 17th June, 2018, the week before the 
presentations start.

During the development of the project there will be weekly lab meetings with my Principal
Investigator, prof. Benjamin Haibe-Kains, where the development of the project will be 
discussed. There, I should show my work done and how to approach each of the problems as
they appear.
w
Every week there's a lab meeting. Its objective is to show the development and improvements 
of different lab members and receive feedback. Once in a while, I will be showing my work
done there.

It must be noticed that the initial planning can be revised and updated as a result of the 
project's evolution, feedback received from the lab members and from my Principal Investigator. 

\ssecc{Tasks}

\sssecc{Acquire background in Convolutional Neural Networks}

Since the \gls{PMHNK} dataset has imaging data, \glspl{CNN} will be using to filter and analyze
the images. So, the first step is to acquire a better understanding in how this type of Neural
Networks work.

As a basic support in statistics applied to \emph{Machine Learning}, I will have the book 
\emph{The Elements of Statistical Learning}. Moreover, I will be doing three different online 
courses to get a full understanding in Neural Networks and \glspl{CNN} to see how they work
and how they can be used. 
~\cite{neural:elements-statistical-learning}

The three courses are made by \href{https://www.deeplearning.ai}{Deeplearning.ai}
and published at Coursera~\cite{neural:coursera} related to Convolutional Neural Networks:
\begin{itemize}
  \item \href{https://www.coursera.org/learn/neural-networks-deep-learning}{Neural Networks and 
    Deep Learning}~\cite{neural:coursera:nn}: Where the basic elements of a neural network and how
    to train it are explained.

  \item \href{https://www.coursera.org/learn/deep-neural-network}{Improving Deep Neural Networks: 
    Hyperparameter tuning, Regularization and Optimization}
    ~\cite{neural:coursera:nn-hyperparameters}: 
    In this course, it's shown the importance of hyperparameters and how each one works. 
    This way then it can be easier to design a proper network and understand all the options that
    many deep learning libraries like \emph{tensorflow} can offer. Also, the different methods 
    of regularization and how to implement them are explained too. This way, avoiding overfitting
    should be easier.

  \item \href{https://www.coursera.org/learn/convolutional-neural-networks}{Convolutional Neural 
    Networks}~\cite{neural:coursera:cnn}:
    How the \emph{convolution} operation works and why it's used in Machine Learning. 
    Different methods of using a Convolutional Neural Network, like face recognition or 
    object detection, are explained with exercises for the student.
\end{itemize}

All the tasks should be done in three weeks.

\sssecc{Get familiar with survival models like DeepSurv}

Survival Prediction models are a bit different from the usual Machine Learning problem. Since, 
in this case, there is \glsdisp{censoring}{censored} data some data cannot be used always. Also, 4
we want to obtain the survival function \( S(t) \) or the hazard function \( \lambda(t) \) 
which is not directly provided in the dataset, as our output values are the \gls{event} 
\glssymbol{event} and the \gls{time} \glssymbol{time}.

DeepSurv is a machine learning package, with a published paper, using a survival model. In this
case the model used is \gls{CPH} which is not the same I will be planning to use.

To see how to properly use a survival model in a deep learning application I should fully 
understand how this is applied in the construction of the DeepSurv neural network. During 
the task I should compare the code implementation with the theoretical models so this way
I can see how to properly use \emph{vectorization} to speed-up computation
\cites{medical:cox}{medical:deep-surv}.

This process will take around two weeks.

\sssecc{Preprocess data}

The input data for this project are:
\begin{itemize}
  \item RAW data from \gls{CT} scans. There are around 100 slices for each patient, each one of 
  a size of \( 512 \times 512 \) pixels.
  \item Tumour annotations for the CT scans. For each RAW slice there's another one which is an
  annotated mask with 1s in the pixels containing tumour and 0s otherwise.
  \item Clinical data. Which has information for each patient such as:
  \begin{itemize}
    \item Age
    \item Gender
    \item Smoking Pack Years
    \item Treatment
    \item Survival time
    \item Survival event
  \end{itemize}
\end{itemize}

This imaging data needs to be preprocessed, and multiple steps need to be followed:

\begin{enumerate}
  \item Obtain the tumour bounding box
  \item Extract the 3D slice contained in the bounding box
  \item Normalize to a value \( x \in [0, 1] \)
  \item Resize the image to a a size of \( 64 \times 64 \times 64 \) voxels.
  \item For data augmentation add random crops and rotations to the image before extracting the 3D
  slice
\end{enumerate}

These operations can be done in the period of a week.

\sssecc{Get familiar with Tensorflow}

Tensorflow\cite{neural:tensorflow} is one of the biggest libraries for \gls{DNN}.
It has high level methods that allow the user to create their own model without having to know
the underlying implementation. So, this way, they do not have to know how to compute the
derivatives for each operation, required to implement the back propagation algorithm. Also,
it's an open source package so it comes at no cost.

Since it's a big piece of software and it offers many possibilities, it's very important to 
understand how it works and what is the best way to use it. The first step is to start by 
just being able to run the simple code that comes with the tutorials. Then, I should build
some simple models to test and see how to properly use the \texttt{Tensor} class that it
provides to create a computing graph and do the mathematical calculations.

This task won't take more than a week.

\sssecc{Build shallow siamese network}

A siamese network is a type of neural network that is suited for comparison tasks such as 
face recognition or signature verification \cite{neural:siamese:signature}.
Its design usually is made of two networks, usually called sisters. The output of the 
two sisters gets joined in an additional layer, called \gls{contrastive}, that compares
the outputs. Finally, this layer produces the final output, which is usually used for 
classification, an example of siamese network can be found on \autoref{fig:siamese}.

Usually, the two sister networks share the same parameters and architecture so after one 
is designed then it's duplicated and added the \gls{contrastive} layer.

Through this approach, the survival problem will be transformed into a order learning problem
where for two elements \( x_1 \) and \( x_2 \) the network learns the sorting function
\( f(x_1, x_2) = \hat{T}(x_1) > \hat{T}(x_2) \), where \( \hat{T}(x) \) is the predicted 
survival time. Not that the network will not learn the predicted survival time, just if one
is bigger than the other.

To build this model, a proper design for the sister network must be done first. This, will be
an iterative task where the proposed model will be created and then, trained optimizing
the hyperparameters. Afterwards, a new change will be made trying to get better results and
it will be compared against the previous one. 

The starting point can be seen in \autoref{fig:shallow-sister} which is inspired in a paper
\cite{neural:hand-eye-coordination} published by Google where they made a combination of 
scalar and image inputs in a Convolutional Neural Network. So the network will try to combine
both the imaging data (the \gls{CT} scans) and scalar data such as the clinical data and the
radiomic features extracted from the image.

Then the results will be compared and some few changes will be made to try to get better results.

\begin{figure}
  \centering
  \input{drawings/siamese_network.tikz.tex}
  \caption{Siamese Network basic structure \label{fig:siamese}}
\end{figure}

\begin{figure}
  \centering
  \input{drawings/shallow_network.tikz.tex}
  \caption{Shallow sister network design \label{fig:shallow-sister}}
\end{figure}

This is one of the most important parts of the project, since it will have a huge
impact in the final results. It will take around four weeks to complete more or less
and it will be a trial and error process to try to see which architecture for the sister
network is best suited to solve the problem.

In this phase the designed networks will be very shallow to make small and fast improvements
since the training time could be an issue.

\sssecc{Build deep siamese network}

Once an initial shallow network is already created, then the next step will be to try 
and create a more deep version. To do so, it will be done step by step adding one layer
at a time and seeing how the network is performing.

The main advantage of deep networks against shallow networks is that they are able to
identify more complex features and thus they usually perform better. However, its 
main drawback is that training time is longer and therefore, the development process is 
slower.

\sssecc{Compare the model against other ones}

Once the final deep model is created, it will be compared against different methods of 
survival analysis. Since this method will be the first one using both image data and scalar 
data it will be compared against models using only one or the other. 

To compare the model, the \gls{CV} \gls{CI} needs to be obtained first. Afterwards,
it will be compared against models trained using the same dataset, using the 
\emph{radiomic} features extracted with PyRadiomics but using
a \gls{CPH} model instead.
~\cites{medical:py-radiomics}{medical:cox}

To do all the comparisons, the \gls{PMHNK} will be trained with each model multiple times.
That's why this task will take around to weeks to complete.

\ssecc{Estimated time}

In \autoref{tab:time} an estimation of the number of hours dedicated to each task is shown.

\begin{table}[H]
  \centering{}
  \begin{tabular}{|l|r|}
    \hline
    Task & Estimated duration (h) \\ \hline \hline
    Acquire background in CNN & 120 \\ \hline
    Get familiar with survival models & 80 \\ \hline
    Preprocess data & 40 \\ \hline
    Build shallow siamese network & 200 \\ \hline
    Build deep siamese network & 80 \\ \hline
    Compare models & 80 \\ \hline
    Final stage & 160 \\ 

  
    \hline \hline
    \textbf{Total} & 760 \\
    \hline
  \end{tabular}
  \caption{Estimated time for each task \label{tab:time}}
\end{table}

\ssecc{Gantt chart}

\autoref{fig:gantt} shows the planning of the different tasks of the project in a Gantt chart.

\begin{figure}[H]
  \centering{}
  \def\gantttext{4cm}
  \begin{tikzpicture}
  \begin{ganttchart}[
      time slot format=isodate,
      x unit = .9mm,
      y unit title = 0.7cm,
      y unit chart = 0.5cm,
      group label font = \tiny\bfseries,
      title label font = \tiny,
      bar label font = \tiny,
      vgrid={*{4}{draw=none},dotted,*{2}{draw=none}},
      hgrid,
      calendar week text = {\startday},
      link bulge = 2,
    ]{2018-02-14}{2018-06-29}
    \gantttitlecalendar{month=shortname, week} \\


    % Start gantt itself
    \ganttgroup{Preamble}{2018-02-14}{2018-03-25} \\
    \ganttbar{Getting started}{2018-02-14}{2018-02-18} \\
    \ganttlinkedbar{Learn about CNN}{2018-02-19}{2018-03-11} \\
    \ganttlinkedbar{Learn about DeepSurv}{2018-03-12}{2018-03-25} \\

    
    \ganttgroup{Build siamese network}{2018-03-26}{2018-05-20} \\
    \ganttbar{Preprocess data}{2018-03-26}{2018-04-01} \\
    \ganttlinkedbar{Build shallow network}{2018-04-02}{2018-05-06} \\
    \ganttlinkedbar{Build deep network}{2018-05-07}{2018-05-20} \\

    \ganttgroup{\parbox[r]{2.3cm}{Compare models and extract conclusions}}{2018-05-21}
    {2018-06-03} \\

    \ganttbar{Compare models}{2018-05-21}{2018-05-27} \\
    \ganttlinkedbar{Extract conclusions}{2018-05-28}{2018-06-03} \\

    \ganttgroup{Final Stage}{2018-06-04}{2018-06-29} \\
    \ganttbar{Write final report}{2018-06-04}{2018-06-17} \\
    \ganttbar{End project}{2018-06-18}{2018-06-24} \\
    \ganttbar{Presentation}{2018-06-25}{2018-06-29} \\

  \end{ganttchart}
  \end{tikzpicture}
  \caption{Gantt chart of the project \label{fig:gantt}}
\end{figure}

\ssecc{Action plan}

As it has already been said, the fact that there will be weekly meetings will allow to 
revise and adapt the initial planning. This means that, for each task, the real duration, 
compared to the planned one may differ, and thus the planning will be changed accordingly. 
If a task is finished before planned, then the next task will start immediately. 
Moreover, if a task duration is longer than expected, then the following tasks will need 
to be rescheduled or, in the worst case, omitted, although not all the tasks can be excluded.

Having weekly meetings with the Principal Investigator should mitigate the possible problems,
and give enough time to detect possible delays or differences with the original time. Therefore,
I should be able to fix them as soon as they are detected.

Below, there are some examples of potential sources of delays.

\sssecc{Complexity of the built model}

Since the model that it's going to be built is quite complex, it will have a constant trial
and error. This can cause delays if a wrong architecture it's chosen, and it's not detected
on time, because a lot of time can be lost trying to optimize a wrong model,
until it's noticed. 

\sssecc{Bugs}

Using complex software such as Tensorflow is prone to errors in many ways. Programming errors
are not an exception and while writing the code some bugs can be introduced. If a bug is not 
noticed soon, it can cause long delays while trying to fix them.

\sssecc{Unavailability of \acrlong{CC}}

Since this project involves training \glspl{CNN}, it needs a lot of computing 
power so \gls{CC} computing cluster will be used to train the data. If the cluster it's not available,
then the training will need to be done with local resources which will be slower and thus 
more time will be lost.

\sssecc{Training times}

The training time is one of the biggest drawbacks of this project. Since this task
can take a huge amount of time depending on the chosen architecture it can cause
huge delays in the original plan. This should be mitigated by doing small tests
instead of a whole training session to make sure that no bugs are found in the code 
because, otherwise, all the training results would become invalid.

\ssecc{Project budget \label{sec:budget}}

In order to carry out this project some resources will be needed. In this document, 
an estimation of the cost of the project is presented, keeping in mind the required
hardware and software resources, and its corresponding amortizations. Also, the
indirect costs of the project are counted too.

\sssecc{Hardware budget}

In order to implement the different models previously explained, some hardware will be
needed. The training will usually be done in Compute Canada computing platform. The
access to the different provided clusters it's provided by the Bioinformatics and 
Computational Genomics Laboratory.

\autoref{tab:hardware-budget} shows an estimation of the cost of the hardware used in the
project, taking into account its useful life and its amortizations.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|r|r|r|}
    \hline
    \textbf{Product} & \textbf{Price} & \textbf{Units} & \textbf{Useful life} 
    & \textbf{Amortization} \\ \hline\hline

    MSI GL62M 7RD-429XES & 1.000 € & 1 & 5 years & 83 € \\ \hline
    Lab iMac & 0 € & 1 & -- & 0 € \\ \hline
    Compute Canada platform & 0 € & 1 & -- & 0 € \\ \hline

    \hline\hline
    \textbf{Total} & 1.000 € & \multicolumn{2}{|c|}{} & 83 € \\ \hline
  \end{tabular}
  \caption{Hardware budget \label{tab:hardware-budget}}
\end{table}

\sssecc{Software budget}

Some software will be used to carry out the project. Since this project will be used using
Open Source and free tools the total software cost of the project is zero. 
\autoref{tab:software-budget} shows an estimation of the cost of the software used in the 
project.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Product} & \textbf{Price} & \textbf{Units} & \textbf{Amortization} \\ \hline\hline

    Python & 0 € & 1 & 0 € \\ \hline
    Tensorflow & 0 € & 1 & 0 € \\ \hline
    PyDicom & 0 € & 1 & 0 € \\ \hline
    NumPy & 0 € & 1 & 0 € \\ \hline
    Scikit & 0 € & 1 & 0 € \\ \hline
    Visual Studio Code & 0 € & 1 & 0 € \\ \hline
    Git & 0 € & 1 & 0 € \\ \hline
    GitHub & 0 € & 1 & 0 € \\ \hline
    PyCharm Community Edition & 0 € & 1 & 0 € \\ \hline
    \LaTeX & 0 € & 1 & 0 € \\ \hline
    Vim & 0 € & 1 & 0 € \\ \hline

    \hline\hline
    \textbf{Total} & 0 € &  & 0  € \\ \hline
  \end{tabular}
  \caption{Software budget \label{tab:software-budget}}
\end{table}


\sssecc{Human resources budget}

To develop this software some roles will be taken. There will be the Project Manager role,
the Software Developer role and the Tester role. Each role is differentiated in the total
of 760 hours. \autoref{tab:salary} shows the estimated costs for each role and the
Human Resources cost, \autoref{tab:time-estimation} shows an estimation of the time 
inverted on each role for each task.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Role} & \textbf{Hours} & \textbf{€/hour} & \textbf{Salary} \\ \hline\hline

    Project Manager & 70 & 33,8 & 2.366 € \\ \hline
    Software Developer & 510 & 23,4 & 11.914 € \\ \hline
    Tester & 180 & 19,5 & 3.510 € \\ \hline

    \hline\hline 
    Total & 760 & & 17.810 € \\
    \hline
  \end{tabular}

  \caption[Human Resources budget]{
    Human resources budget, salary according to \cite{ine:salary} \label{tab:salary}
  }
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{|P{4cm}|r|r|r|r|}
    \hline
    \multirow{2}{*}[-1em]{\textbf{Task}} & 
    \multirow{2}{*}[-1em]{\textbf{Duration}} & 
    \multicolumn{3}{|c|}{\textbf{Dedication}} \\ \cline{3-5}

     & & \parbox[c][1.5cm]{2.1cm}{\textbf{Project \\ Manager}} & 
     \parbox[c][1.5cm]{2.2cm}{\textbf{Software \\ Developer}} & 
     \textbf{Tester} \\ \hline\hline

     Acquire background in CNN & 120 & 10 & 110 & 0 \\ \hline
     Get familiar with survival models & 80 & 10 & 70 & 0 \\ \hline
     Preprocess data & 40 & 10 & 20 & 10 \\ \hline
     Build shallow siamese network & 200 & 15 & 110 & 75 \\ \hline
     Build deep siamese network & 80 & 10 & 50 & 20 \\ \hline
     Compare models & 80 & 10 & 40 & 30 \\ \hline
     Final stage & 160 & 5 & 110 & 45 \\ 

     \hline\hline
     \textbf{Total} & 760 & 70 & 510 & 180 \\
     \hline
  \end{tabular}

  \caption{Time estimation by role \label{tab:time-estimation}}
\end{table}

\sssecc{Unexpected costs}

As there may be unexpected changes in the project, an extra budget has to be added to compensate
for such problems. \autoref{tab:unexpected-costs} shows the distribution of this budget per role.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Role} & \textbf{Hours} & \textbf{€ / hour} & \textbf{Salary} \\ \hline\hline
    Project Manager & 10 & 33.8 & 338 € \\ \hline
    Software Developer & 20 & 23.4 & 468 € \\ \hline
    Tester & 10 & 19.5 & 195 € \\ \hline

    \hline\hline
    \textbf{Total} & 40 & & 1001 € \\ 
    \hline
  \end{tabular}
  \caption{Unexpected costs \label{tab:unexpected-costs}}
\end{table}

\sssecc{Indirect costs}

In a project, there are some costs that cannot be added in neither of the previous categories,
this are estimated in \autoref{tab:indirect-costs}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Product} & \textbf{Price} & \textbf{Units} & \textbf{Cost} \\ \hline\hline

    Electricity & 0,12 €/kWh & 550 kWh & 66 € \\ \hline
    Internet + phone & 70 €/month & 4 months & 280 € \\ \hline
    
    \hline\hline
    \textbf{Total} & & & 346 € \\ \hline
  \end{tabular}
  \caption{Indirect costs \label{tab:indirect-costs}}
\end{table}

\sssecc{Total budget}

By adding all the previously provided budgets, the total estimated budget for this project
is obtained, as shown in table \autoref{tab:total-costs}. Notice that a 5\% of contingency
has been added over the cumulative total in order to cover unexpected expenses that may 
occur during the development of the project.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|}
    \hline
    \textbf{Concept} & \textbf{Estimated Costs} \\ \hline\hline

    Hardware resources & 83 € \\ \hline
    Software resources & 0 € \\ \hline
    Human resources & 17.810 € \\ \hline
    Unexpected costs & 1001 € \\ \hline
    Indirect costs & 346 € \\ \hline

    \hline\hline
    \textbf{Subtotal} & 19.240 € \\
    \hline\hline
    Contingency (5\%) & 962 € \\
    \hline\hline
    \textbf{Total} & \textbf{20.202 €} \\ \hline
  \end{tabular}

  \caption{Total project costs \label{tab:total-costs}}
\end{table}

Finally, an estimation of the approximate budget per task is also provided in 
\autoref{tab:task-cost}. The cost of each task is computed using the number of hours spent 
in the task and the required resources.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|}
    \hline
    \textbf{Task} & \textbf{Estimated cost} \\ 
    \hline\hline

    Acquire background in CNN & 3.189,79 € \\ \hline
    Get familiar with survival models & 2.126,53 € \\ \hline
    Preprocess data & 1.063,26 € \\ \hline
    Build shallow siamese network & 5.316,32 € \\ \hline
    Build deep siamese network & 2.126,53 € \\ \hline
    Compare models & 2.126,53 € \\ \hline
    Final stage & 4,253.05 € \\ 

    \hline\hline
    \textbf{Total} & 20.202,00 € \\ \hline
  \end{tabular}

  \caption{Project's tasks costs \label{tab:task-cost}}
\end{table}

\ssecc{Budget control}

Controlling the spent budget is a very important part of the project. Using too much time or 
having to buy unexpected hardware could be a problem but it's likely to happen. That's why
some plans will be made to avoid, as much as possible, this situation.

It may be necessary to buy extra software or to have more human resources although it's
unlikely that it may be necessary more hardware. Solving the extra software requirement
shouldn't be a big problem as there are many free or open source software solutions in
the market.

To control the human resources budget, the number of hours working as each role will be 
recorded, this way then it can be seen if too much time has been used for a task and then
it can be solved by rescheduling the next tasks.

\ssecc{Sustainability and social commitment}

In order to evaluate the project's sustainability, environmental impact will be analyzed
regarding three major factors: environmental, social and economical. The analysis will be 
based in the application of the sustainability matrix to the project shown in
\autoref{tab:sustainability} and in the poll that can be accessed through 
\url{https://goo.gl/kWLMLE}.

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \cline{2-4}
    \multicolumn{1}{c|}{} & \textbf{PPP} & \textbf{Useful life} & \textbf{Risks} \\ 
    \hhline{-===}

    \multirow[c]{2}{*}{\textbf{Environmental}} & 
    \makecell{Design \\ consumption} & \makecell{Ecological \\ footprint} & 
    \makecell{Environmental \\ risks} \\ \cline{2-4}
    & 2/10 & 19/20 & -2/-20 \\ \hline
    
    \multirow{2}{*}{\textbf{Economical}} & 
    Bill & \makecell{Viability \\ plan} & \makecell{Economical \\ risks} \\ \cline{2-4}
    & 7/10 & 18/20 & -15/-20 \\ \hline

    \multirow{2}{*}{\textbf{Social}} &
    \makecell{Personal \\ impact} & \makecell{Social \\ Impact} & 
    \makecell{Social \\ risks} \\ \cline{2-4} 
    & 9/10 & 18/20 & -5/-20 \\ \hline

    \hline\hline
    \multirow{2}{*}{\parbox[c]{3cm}{\centering\textbf{Sustainability \\ range}}} &
    18/30 & 55/60 & -22/-60 \\ \cline{2-4}
    & \multicolumn{3}{c|}{51/90} \\ \hline

  \end{tabular}
  \caption{Project's sustainability matrix \label{tab:sustainability}}
\end{table}

\sssecc{Evaluation}

Nowadays sustainability is a great issue, the progress made by humanity in the technology
field it has some consequences too. Information and Communication Technologies are not 
an exception although it has taken some time to gain importance. The appearance of 
small devices like smartphones and the huge power requirements of big data centers have 
helped in gaining conscience of power consumption. 

When trying to build a new project now it's important to see project's sustainability. If the
project involves building some hardware then it may have a negative impact on the environment
so proper measures need to be taken to avoid future problems.

Moreover, if the project it's software related then it has some implications too. In general
when working with this type of projects the only part where it can be a problem is regarding
power consumption, which is usually related to efficiency. As a general rule they should
avoid using too much power but it depends on the project's type. Machine Learning ones
usually have a big power consumption during the training phase since it requires a huge
amount of computational power. However, smartphone related applications tend to have less
consumption to allow for a longer battery life.

However, regarding the budget, solutions that tend to be more sustainable usually are more
expensive. When it is attempted to reduce consumption in software projects, this usually 
translates in more programmer hours and thus a higher budget.

\sssecc{Environmental dimension}

Regarding the environmental dimension the project has two main stages. Since the main objective
of the project is to develop a deep learning model the first stage is to create the model
itself. The second one is to deploy the product and start using it.

In the first stage many resources will be needed since the training process in machine learning
requires a huge amount of computational power. This is directly translated to electricity 
consumption so, during the development process the environmental impact will be hight.

However, once a model is already trained, using it does not require much power since the
data inference it's quite fast and thus, does not require many electricity consumption.
That's why the second part of the project won't have a very hight environmental impact.

\sssecc{Social dimension}

As there is a lot of research regarding this topic, creating this project should help pushing 
forward the development of new methods for survival analysis. Either if the project results 
are positive or negative it should help to prove that a certain method is valid or not. 

In addition, it's primary focus is medical, so it's very social oriented. Thus,
in the long term, it should help cancer patients to receive better treatments 
that will be developed with help of survival analysis models. 

Regarding the personal and ethical implications, it will help having a better understanding
of machine learning models, how to use them and how to develop them. Moreover, this project
will not have any ethical issue but the contrary, knowing that the social outcome can be
positive it's an incentive to work and do a good job.

\sssecc{Economical dimension}

A detailed exposition of all the related project costs has already been made including both
human and material resources, as shown in \autoref{sec:budget}.

This project should have a positive impact regarding the economical dimension. Improving
the methods for survival detection helps reducing the costs of future research. However, 
there's the downside that if the research has some kind of mistake that it's not noticed,
a negative impact may occur due to the fact that some related researches may have to roll
back some results.

