% !TEX root = main.tex

\secc{Context and scope of the project}
\ssecc{Context}

Nowadays one of the most extensive uses of computing is artificial intelligence. A few 
examples are Amazon purchase recommendations, based on previous purchases, or help users
to interact with their phone by only using voice commands like Google Assistant. 
~\cites{neural:amazon}{neural:google-assistant}

Inside AI one of the domains that has greatly increased during the last years is 
\emph{Machine Learning}. The main advantage is that it can solely learn from examples without 
explicit teaching, and thus reducing the human interaction during the learning process. One of the 
most used types is \emph{deep neural networks} and these have demonstrated impressive performance 
against computer vision and Natural Language Processing tasks like the classification of 
digits from the MNIST data set.
~\cites{neural:mnist}{neural:empirical-evaluation-deep-architectures}

Regarding the medical field, recent deep learning algorithms, specially \gls{CNN} 
have started to push the boundaries of precision medicine. 
Traditionally, medical predictions have been based on a few clinical parameters with poor accuracy.
However, other data types are available to improve such predictions. In this context, medical
images generated from \gls{MRI}, \gls{PET} or \gls{CT} scans are vastly underused 
due to the 
inability of radiologists to quantitatively analyze this complex data.

Different methods have appeared to analyze these images for tasks such as
image classification, object detection, segmentation and registration among other tasks. This
approach started in the late 1990s and has slowly shifted from systems that are completely designed
by humans to systems that are trained by computers using example data. 
~\cite{medical:survey-deep-learning}

Professor Benjamin Haibe-Kains has helped in the development of \emph{Radiomics}, a new field to
relying on pre-defined, hand-engineered features computed from medical images to better 
characterize tumours and predict survival outcome. Although promising, radiomics suffers from 
several limitations. The most important one is that it relies on hand-engineered features,
these features are not guaranteed to be the most discriminant ones. Deep learning methods
are end-to-end and, for a given task, they drive features from the data.
~\cite{medical:radiomics-ml-classifiers}

\sssecc{Survival Analysis}

Survival Analysis is a branch of statistics that analyzes the duration time of the observed
events. Typically it refers to the time to the failure of a physical component or to death of a
patient. It usually defines the following terms~\cite{neural:survival-analysis}:

\begin{description}
  \item[\Gls{event} \glssymbol{event}] \glsdesc{event}
  \item[\Gls{time} \glssymbol{time}] \glsdesc{time}
  \item[\Gls{baseline} \glssymbol{baseline}] \glsdesc{baseline}
  \item[\Gls{censoring}] \glsdesc{censoring}
\end{description}

The survival and hazard functions are the two fundamental functions in survival analysis. The
survival function \( S(t) = \Pr(T \ge t) \), is the probability that an individual has
\emph{survived} beyond time \( t \). The hazard function \( \lambda(t) \) is a measure of risk at 
time \( t \) and it's defined as:
~\cite{medical:cox}
\[
  \lambda(t) = \lim_{\Delta t \rightarrow 0}
  \frac{\Pr(t \le T < t + \Delta t | T \ge t)}{\Delta t}
\]

Casting the survival analysis as a ranking problem is a way of dealing with the biased
distributions of survival times and the censoring data. Two subjects' survival times can be 
ordered only if:
\begin{enumerate}[noitemsep, topsep=0pt]
  \item Both of them are uncensored (\( E_i = E_j = 1\))
  \item The uncensored time of one is smaller than the censored survival time of the other
  (\( T_i < T_j | E_i = 1; E_j = 0 \))
\end{enumerate}

This can be visualized by means of an order graph \( G = (V, E) \), see \autoref{fig:graph-ci}.
The set of vertices \( V \) represents all the individuals, where each filled circle 
(\( \bullet \)) indicates an \emph{uncensored} survival time, while an empty circle 
(\( \circ \)) denotes a \emph{censored} observation.
Existence of an edge \( E_{ij} \) implies that \( T_i < T_j \). An edge cannot originate 
from a censored point.

\begin{figure}
  \centering
  \begin{subfigure}[b]{.4\textwidth}
    \centering
    \input{drawings/graph_no_censored.tikz.tex}
    \caption{No censored data}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{.4\textwidth}
    \centering
    \input{drawings/graph_censored.tikz.tex}
    \caption{With censored data}
    \label{fig:graph-ci:censored}
  \end{subfigure}

  \caption{Order graphs representing the ranking constraints \label{fig:graph-ci}}

  Censored data is represented \( \circ \) and uncensored data is represented by \( \bullet \).
  Every edge \( A \rightarrow B \) means \( T_A > T_B \). Note that in 
  \autoref{fig:graph-ci:censored} some vertex are not connected since an edge 
  \( \circ \rightarrow \bullet \) cannot be formed.
\end{figure}

% C-index explanation
The standard performance measure, to compare if a survival 
model is performing better than another, is the \gls{CI}. To obtain this 
indicator, pairs are generated to compare the survival time. A prediction is counted as good only
if both \( T_i > T_j \) and \( \hat{T}_i > \hat{T}_j \), otherwise
it's counted as a bad prediction, note that \( T_i = \hat{T}_i \) it's not a required condition. 
Then, the number of good predictions is divided by the total predictions. 
~\cite{medical:ranking-ci}

\[
  CI = \frac{\text{Good predictions}}{\text{Total predictions}} \in [0, 1]
\]

Also, another comparison 
element is the \gls{ROC} curve which represents the \emph{False Positive Rate} against the 
\emph{True Positive Rate}, see \autoref{fig:ROC-curve}. Usually the \gls{CI} is seen as 
the area under the \gls{ROC} curve.
~\cite{neural:roc-precision-recall}

\begin{figure}
  \centering
  \includegraphics[width=.5\linewidth]{images/roc_curve}
  \caption{\acrshort{ROC} Curve example\label{fig:ROC-curve}}
\end{figure}

\sssecc{Dataset}

The dataset that this project will be using to develop a model is provided through a 
collaboration with Dr.~Fei-Fei Liu, head of the Radiation Medicine Program at Princess
Margaret Cancer Centre. 

We have access to a unique set of \( {\sim}500 \) Computed Tomography scans of head-and-neck 
cancer patients. Each scan is 512 pixels wide by 512 pixels tall and is composed 
of 100-200 slices in gray scale that together form a 3D image. To be able to slice the tumour
fro the rest of the image, a mask of the same size as the scan is provided. It contains 1s 
if the pixel contains a tumour and 0s otherwise, as it can be seen in \autoref{fig:dataset-example}.

Also, there's the following clinical information for the patients:
\begin{itemize}
  \item Subject characteristics (age, gender, clinical status, smoking, drinking history)
  \item Tumor characteristics (cancer location, staging, p16 status)
  \item Treatment data (modality, radiation start/end dates, radiation dose/fractionation, 
  treatment completion status)
  \item Outcome data (status, cause of death, local failure, regional failure, distant failure)
\end{itemize}

\begin{figure}
  \centering
  \begin{subfigure}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/IMG_example.png}
    \caption{Original image}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/IMG_MASS_example.png}
    \caption{Image mask}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/IMG_merge_example.png}
    \caption{Mask applied to original}
  \end{subfigure}

  \caption{Example of images from the dataset \label{fig:dataset-example}}

  Single CT's scan slice, a whole scans is composed of multiple slices. By applying the mask to 
  the original image, the part of that only contains the tumour can be extracted.
\end{figure}


\ssecc{State-of-the-art}

Nowadays, a lot of research is being done in the medical field using deep learning. Image
classification is one of the first areas in which there's a major contribution to medical analysis.
Usually in image classification there are one or multiple images as input and a single diagnostic 
variable as output (e.g.~ill or not).
~\cite{medical:survey-deep-learning}

Regarding the prediction of survival models, there have been different approaches although
almost all of them use MRI, PET or CT scans and the clinical data. The typical one is to extract
hand-crafted radiomic features using own methods or using libraries such as
\href{https://github.com/Radiomics/pyradiomics}{\emph{PyRadiomics}}. This hand-crafted 
features are usually based in aspects like tumour shape, intensity, volume or texture.
~\cites{medical:tumour-radiomics}{medical:py-radiomics}

An alternative approach, is to use a deep learning-based model for prediction and for feature
extraction. In this case, features are extracted too but a \acrshort{CNN} 
is used instead. With this approach the use of transfer learning has been a
great improvement. Pre-trained networks are used to reduce the requirement of large data
sets for deep network training. Usually, there are two possible strategies: 
\begin{itemize}[noitemsep, topsep=0pt]
  \item Using a pre-trained NN as a feature extractor
  \item Fine-tuning a pre-trained network on medical data.
\end{itemize}

Both strategies are popular and have been widely applied. A network that allows this type
of retrain is GoogLeNet Inception v3
~\cites{neural:goog-le-net}{neural:retrain}{neural:inception-retrain}.
However, there's the added problem that medical imaging data are usually 3D images but, 
when working with pre-trained CNN, only 2D images can be used, because there are still no 
pre-trained networks on 3D images. Although this method seems promising, still requires 
further work to train a dedicated feature extractor explicitly designed for medical images.
~\cite{medical:deep-learning-radiomics-gbm}

An implemented survival prediction model is \emph{DeepSurv} which is based on survival data
and uses the Cox Proportional Hazards model for an individual's survival given the baseline data
\( x \). It's an Open Source Python module that applies recent deep learning techniques 
to a Cox model.
~\cites{medical:deep-surv}{medical:cox}

% TODO: Add 3D imaging field
In the 3D imaging filled there has been some work already. 3D Convolutional Neural Networks have
been used for brain lesion segmentation on multi-channel MRI scans. \cite{neural:3d-cnn-crf}

\ssecc{Problem Formulation}

The goal of this project is to develop a new deep learning model to analyze this private 
dataset in combination with public databases to improve the prediction rate of patients' 
survival compared to models built on traditional radiomic features. We would like to 
investigate and compare the performance of the deep learning-based method 
to the more conventional methods, such as hand-engineered radiomics features and the tumor 
\emph{volume} feature which is often used in clinic as a prognostic feature. The C-index 
of the volume for the set of patients at hand, is ~0.65.

\ssecc{Stakeholders}

\sssecc{Developer}
Is the person in charge of the research, document and implement all the required software.
In addition he is responsible for the project management and the writing of the report
and all the required documentation. This actor works as agreed with the director and
he is, ultimately, the person in charge of accomplishing the deadlines.

\sssecc{Director}
He is the main responsible for guiding, giving advice and, in general, helping the developer.
His action is key to determine possible errors in the project, both in its proposal and 
execution. In particular, Benjamin Haibe-Kains from the Bioinformatics and Computational
Genomics Laboratory has acted as director
~\cites{bhklab}.

\sssecc{Beneficiaries}
The project beneficiaries will depend on its outcome. If a more efficient model is found, the
beneficiaries will be the researchers trying to test a new cancer treatment method. Moreover,
the final patient will also be benefited because more modern research techniques will be used.

However, if a more efficient model is not found, the beneficiaries will be the researchers
trying to find the best model for survival analysis since this would have proved which 
methods do not work well.

\ssecc{Scope}

The first task will be to learn and to understand how Neural Networks and specifically how 
Convolutional Neural Networks Work. This way I will have a fully understanding of the background
that all these methods use to create models for survival prediction.

The next task will be to set up and to run the \emph{DeepSurv} python package on a local
computer. Once running, all the different parts of the package should be tested to see which
ones are best suited to be reused to create a new Survival Prediction Model. Since the package
is not prepared to have images as an input, an improvement will be to add the possibility to 
pass medical images to train the survival model.
\cite{medical:deep-surv-github}

Afterwards, a deep learning model will be created starting from zero but trying to use 
some ideas from other completed projects. This model, unlike \emph{DeepSurv}, will not be 
using the Cox Proportional Hazards because, in this case, the approach will be to compare
pairs and not to get the hazard function. Since the C-index is computed using pairs of patients, 
a siamese neural network will be built. This type of network is suited for comparison 
tasks such as face recognition, but this time it will be comparing the pair's survival time.

\ssecc{Methodology}

This project is part of a research project at Benjamin Haibe-Kains Bioinformatics and 
Computational Genomics Laboratory \cite{bhklab}. This means that every week there will be a 
laboratory meeting where different members will be presenting their progress and feedback will
be received accordingly. Once in a while this project's progress will be presented there.
Moreover, a weekly meeting with the Principal Investigator will be scheduled to discuss
the progress made.

Also since there are different ways of development this means that it will have a process of trial
and error until the proper solution is found. This means that during this process the
tasks will be assigned on a weekly basis.


\ssecc{Possible obstacles and solutions}

\sssecc{Training time}

Since this project involves Convolutional Neural Networks training time can be a problem. 
The convolution operation is computationally expensive, so depending on the network the 
training time can be of several days. Also, while just inferring the values does not require
much power, training needs a lot more power. 

To solve this problem the training will be done at \emph{SharcNet} a computing facility. 
This way the training will be much faster.

\sssecc{Monitoring Tools}

The work will be done with the help of Git and GitHub. This tools will help monitoring
the project's evolution. The purpose of Git is to be able to do small revisions,
named commits, and to document all the different changes in the project. Also it has
some tools to allow multiple contributors in the same project. Moreover,
Git projects can be stored in a server, GitHub it's an online platform that allows
remote Git repositories, also it has integrated an issue system, a milestone system
and it's really integrated with Git's contributor system.
~\cites{tool:git}{tool:github}

\sssecc{Bugs}

Considering the software development process, it's no big surprise that it's really easy to
introduce bugs while writing or modifying the source code. To ensure no bugs are present,
some unit tests will be written to check if the model is still giving correct results.
However, this will be a difficult task since it's not easy to check whether a deep 
learning model is just overfitting or that it's giving wrong results.

\sssecc{Scheduling}

Although four months seems plenty of time, spending more time than estimated in a single task
can happen. To avoid this problem weekly meetings will be scheduled with my Principal Investigator
to see which is the best way to continue to keep on track.

\sssecc{Not enough data}

Since the starting dataset is quite small (\( \sim 500 \) samples) overfitting may be a problem
and different methods should be used to avoid it. The possible solutions are:
\begin{itemize}
  \item Using regularization to avoid units with a very high weight.
  \item Using dropout to force each unit to learn with part of the data, and thus generalize.
  \item Using data augmentation techniques such as random crops or random rotations to increase
  the number of images in the dataset.
\end{itemize}
