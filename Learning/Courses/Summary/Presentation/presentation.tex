\documentclass{beamer}

\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{fontspec}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{bm}

\pgfplotsset{compat=1.15}
\usetikzlibrary{positioning, shapes, calc, arrows}

\usetheme{Montpellier}
\usecolortheme{crane}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{caption}[numbered]

\title{Convolutional Neural Networks Summary}
\date{\today}
\author[Joan]{Joan Marc√® i Igual}
\institute[UHN]{University Health Network}

\begin{document}
\begin{frame}
	\titlepage
\end{frame}
\begin{frame}{Table of Contents}
	\tableofcontents
\end{frame}

\section{Introduction}
\begin{frame}{\secname}
	Neural Networks are a type of supervised learning. So we have a set of labeled data:
	$$\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ..., (x^{(m)}, y^{(m)})\}$$
	
	We want to use it to predict new data $\hat{y} = f(x)$
	
	\textbf{Problem}: search the proper $f(x)$
\end{frame}
\section{Neural Networks}
\begin{frame}{\secname}
	\input{neural_network.tikz.tex}
\end{frame}
\subsection{Parameters}
\begin{frame}{\subsecname}
    \begin{columns}[t]
        \column{.6\textwidth}
        \begin{itemize}
            \item $l$: Current layer
            \item $w_{i, j}^{[l]}$: Weight from neuron $j$ to $i$ at layer $l$
            \item $b_{i}^{[l]}$: Bias for neuron $i$ at layer $l$
            \item $a_{j}^{[l]} = g\left( \left( \sum_{j}^{n[l-1]}  w_{i, j}^{[l]} \cdot a_{j} \right) + b_i^{[l]} \right)$
            \item $\bm{a}^{[l]} = g(\bm{W}^{[l]}\cdot \bm{a}^{[l - 1]} + \bm{b}^{[l]})$: Activations for layer $l$
            \item $g(x)$: Activation function
        \end{itemize}
        \column{.5\textwidth}
        \centering
        \input{neural_activations.tikz.tex}
    \end{columns}
\end{frame}
\begin{frame}
    \begin{columns}
        \column{.6\textwidth}
        \begin{block}{Cost function}
            $$
            J(\bm{W}, \bm{b}, \hat{\bm{y}}, \bm{y}) = \frac{1}{m} \sum_{i=1}^{m} \mathcal{L}(\hat{\bm{y}}^{(i)}, \bm{y}^{(i)})
            $$
        \end{block}
        \begin{block}{Loss function}
            $$
            \mathcal{L}(\hat{\bm{y}}, \bm{y}) = ||\hat{\bm{y}} - \bm{y}||^2
            $$
        \end{block}
        \column{.4\textwidth}
        We want to minimize $J(\bm{W}, \bm{b}, \hat{\bm{y}}, \bm{y})$ to get better results for $\hat{y}$.
        \begin{block}{Parameters update}
            \begin{align*}
                \bm{W} &:= \bm{W} - \alpha*\frac{\partial J}{\partial \bm{W}} \\
                \bm{b} &:= \bm{b} - \alpha*\frac{\partial J}{\partial \bm{b}}
            \end{align*}
        \end{block}
    \end{columns}
\end{frame}


\end{document}